{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create sample sentences\n",
    "prediction_file = 'data/predicted_sentences.txt'\n",
    "reference_file = 'data/references.txt'\n",
    "with open(prediction_file, 'w') as f:\n",
    "    f.write('aaa\\tThe University of California San Diego has been ranked the 17th best university in the world.\\nbbb\\tUp four spots compared to last year.\\n')\n",
    "with open(reference_file, 'w') as f:\n",
    "    f.write('aaa\\tThe University of California San Diego has been ranked the 17th best university in the world.\\naaa\\tThe University of California San Diego has been ranked the 17th best university in the world.\\nbbb\\tUp four spots compared to last year.\\nbbb\\tUp four spots compared to last year.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "matplotlib.use('Agg')  # to solve the backend problem when there's no GUI\n",
    "import getopt \n",
    "import hashlib\n",
    "import io \n",
    "import json \n",
    "import os \n",
    "import sys \n",
    "sys.path.append('./coco-caption/') \n",
    "from pycocotools.coco import COCO \n",
    "from pycocoevalcap.eval import COCOEvalCap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CocoAnnotations:\n",
    "  def __init__(self):\n",
    "    self.images = [];\n",
    "    self.annotations = [];\n",
    "    self.img_dict = {};\n",
    "    licenses = [{\n",
    "                \"id\" : \"text\",\n",
    "                \"name\" : \"test\",\n",
    "                \"url\" : \"test\",\n",
    "                }]\n",
    "    self.res = {\"info\" : {},\n",
    "                \"type\" : 'captions',  # should keep type as captions [another choice is istances, though I haven't check]\n",
    "                \"images\" :  self.images,\n",
    "                \"annotations\" : self.annotations,\n",
    "                \"licenses\" : licenses,\n",
    "                }\n",
    "\n",
    "  \n",
    "  def get_image_dict(self, img_name):\n",
    "    image_hash = int(int(hashlib.sha256(img_name).hexdigest(), 16) % sys.maxint)\n",
    "    if image_hash in self.img_dict:\n",
    "      assert self.img_dict[image_hash] == img_name, 'hash colision: {0}: {1}'.format(image_hash, img_name)\n",
    "    else:\n",
    "      self.img_dict[image_hash] = img_name\n",
    "    image_dict = {\"id\" : image_hash,\n",
    "                \"width\" : 0,\n",
    "                \"height\" : 0,\n",
    "                \"file_name\" : img_name,\n",
    "                \"license\" : '',\n",
    "                \"url\" : img_name,\n",
    "                \"date_captured\" : '',\n",
    "                }\n",
    "    return image_dict,image_hash\n",
    "\n",
    "  def read_file(self,filename):\n",
    "    count = 0\n",
    "    with open(filename,'r') as opfd:\n",
    "      for line in opfd:\n",
    "        count +=1\n",
    "        id_sent = line.strip().split('\\t')\n",
    "        assert len(id_sent)==2\n",
    "        sent = id_sent[1].decode('ascii', 'ignore')\n",
    "        image_dict,image_hash = self.get_image_dict(id_sent[0])\n",
    "        self.images.append(image_dict)\n",
    "\n",
    "        self.annotations.append({\n",
    "          \"id\" : len(self.annotations)+1,\n",
    "          \"image_id\" : image_hash,\n",
    "          \"caption\" : sent,\n",
    "          })\n",
    "\n",
    "        if count%1000 == 0:\n",
    "          print 'Processed %d ...' % count\n",
    "\n",
    "  def dump_json(self, outfile):\n",
    "    self.res[\"images\"] = self.images  # should keep it\n",
    "    self.res[\"annotations\"] = self.annotations\n",
    "    res = self.res\n",
    "    with io.open(outfile, 'w', encoding='utf-8') as fd:\n",
    "      fd.write(unicode(json.dumps(res, ensure_ascii=True,sort_keys=True,indent=2,separators=(',', ': '))))\n",
    "    \n",
    "class CocoResFormat:\n",
    "  def __init__(self):\n",
    "    self.res = []\n",
    "    self.caption_dict = {}\n",
    "\n",
    "  def read_file(self, filename):\n",
    "    count = 0\n",
    "    with open(filename,'r') as opfd:\n",
    "      for line in opfd:\n",
    "        count +=1\n",
    "        id_sent = line.strip().split('\\t')\n",
    "        sent = id_sent[1].decode('ascii', 'ignore')\n",
    "        assert len(id_sent) == 2\n",
    "        img_id = int(int(hashlib.sha256(id_sent[0]).hexdigest(), 16) % sys.maxint)\n",
    "        imgid_sent = {}\n",
    "\n",
    "        if img_id in self.caption_dict:\n",
    "          assert self.caption_dict[img_id] == sent\n",
    "        else:\n",
    "          self.caption_dict[img_id] = sent\n",
    "          imgid_sent['image_id'] = img_id\n",
    "          imgid_sent['caption'] = sent\n",
    "          self.res.append(imgid_sent)\n",
    "        if count%1000 == 0:\n",
    "          print 'Processed %d ...' % count\n",
    "\n",
    "  def dump_json(self, outfile):\n",
    "    res = self.res\n",
    "    with io.open(outfile, 'w', encoding='utf-8') as fd:\n",
    "      fd.write(unicode(json.dumps(res,\n",
    "         ensure_ascii=False,sort_keys=True,indent=2,separators=(',', ': '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.001273\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'reflen': 23, 'guess': [23, 21, 19, 17], 'testlen': 23, 'correct': [23, 21, 19, 17]}\n",
      "ratio: 0.999999999957\n",
      "Bleu_1: 1.000\n",
      "Bleu_2: 1.000\n",
      "Bleu_3: 1.000\n",
      "Bleu_4: 1.000\n",
      "computing METEOR score...\n",
      "METEOR: 1.000\n",
      "computing Rouge score...\n",
      "ROUGE_L: 1.000\n",
      "computing CIDEr score...\n",
      "CIDEr: 10.000\n",
      "CIDEr: 10.000\n",
      "Bleu_4: 1.000\n",
      "Bleu_3: 1.000\n",
      "Bleu_2: 1.000\n",
      "Bleu_1: 1.000\n",
      "ROUGE_L: 1.000\n",
      "METEOR: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Assigning output json path\n",
    "reference_json = '{0}.json'.format(reference_file)\n",
    "prediction_json = '{0}.json'.format(prediction_file)\n",
    "\n",
    "# load reference and predicts \n",
    "crf = CocoAnnotations()\n",
    "crf.read_file(reference_file)\n",
    "crf.dump_json(reference_json)\n",
    "\n",
    "crf = CocoResFormat()\n",
    "crf.read_file(prediction_file)\n",
    "crf.dump_json(prediction_json)\n",
    "\n",
    "# create coco object and cocoRes object.\n",
    "coco = COCO(reference_json)\n",
    "cocoRes = coco.loadRes(prediction_json)\n",
    "\n",
    "# create cocoEval object.\n",
    "cocoEval = COCOEvalCap(coco, cocoRes)\n",
    "\n",
    "# evaluate results\n",
    "cocoEval.evaluate()\n",
    "\n",
    "# print output evaluation scores\n",
    "for metric, score in cocoEval.eval.items():\n",
    "    print '%s: %.3f'%(metric, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
